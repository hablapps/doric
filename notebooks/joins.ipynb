{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b060c656",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**<<<<<<< local**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbf9e26",
   "metadata": {},
   "source": [
    "## Spark setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7b695479",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mcoursierapi.MavenRepository\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                  \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                               \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                              \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                               \u001b[39m"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import coursierapi.MavenRepository\n",
    "interp.repositories.update(\n",
    "  interp.repositories() ::: List(MavenRepository.of(\"https://oss.sonatype.org/content/repositories/snapshots\"))\n",
    ")\n",
    "\n",
    "import $ivy.`org.apache.spark::spark-sql:3.1.1`\n",
    "import $ivy.`org.typelevel::cats-core:2.3.0`\n",
    "import $ivy.`com.lihaoyi::sourcecode:0.2.6`\n",
    "import $ivy.`org.hablapps::doric:0.0.0+81-92203c5b-SNAPSHOT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "23e27294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.{functions => f}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mhabla.doric._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mhabla.doric.{functions => doricf}\u001b[39m"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark._\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.{functions => f}\n",
    "import habla.doric._\n",
    "import habla.doric.{functions => doricf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "90ce0eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@1f28f489"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = org.apache.spark.sql.SparkSession.builder().appName(\"test\").master(\"local\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fc490bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mspark.implicits._\u001b[39m"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb461a5",
   "metadata": {},
   "source": [
    "## Typed join expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4d4670",
   "metadata": {},
   "source": [
    "Spark column expressions are subject to the same problems that we explored [previously](\"README.ipynb): lack of static typing, unreported errors at DataFrame compile-time, unprotected implicit castings, etc. For instance, given the following DataFrames:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257c9051",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**=======**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "477636fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mleftdf\u001b[39m: \u001b[32mDataFrame\u001b[39m = [id-left: int, id: int ... 1 more field]\n",
       "\u001b[36mrightdf\u001b[39m: \u001b[32mDataFrame\u001b[39m = [id-right: int, id: int ... 1 more field]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val leftdf = List((1, 1, \"hi\"), (2, 2, \"bye\"), (3, 3, \"3\")).toDF(\"id-left\", \"id\", \"value-left\")\n",
    "val rightdf = List((1, 1, \"hi\"), (2, 2, \"bye\"), (3, 3, \"3\")).toDF(\"id-right\", \"id\", \"value-right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b020da",
   "metadata": {},
   "source": [
    "the following equi-join expressions, where we use different mechanisms to refer to the corresponding columns, compile and run without problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "41f0fc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres44_0\u001b[39m: \u001b[32mDataFrame\u001b[39m = [id-left: int, id: int ... 4 more fields]\n",
       "\u001b[36mres44_1\u001b[39m: \u001b[32mDataFrame\u001b[39m = [id-left: int, id: int ... 4 more fields]\n",
       "\u001b[36mres44_2\u001b[39m: \u001b[32mDataFrame\u001b[39m = [id-left: int, id: int ... 4 more fields]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leftdf.join(rightdf, f.col(\"id-left\") === f.col(\"id-right\"))\n",
    "leftdf.join(rightdf, leftdf(\"id\") === rightdf(\"id\"))\n",
    "leftdf.alias(\"left\").join(rightdf.alias(\"right\"), f.col(\"left.id\") === f.col(\"right.id\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce498a34",
   "metadata": {},
   "source": [
    "However, if some column name or type is wrong, then errors will be shown too late, or implicit type casts will be applied. For instance, the following DataFrame compiles in Spark and runs with garbage results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e7dc0133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mdfjoin\u001b[39m: \u001b[32mDataFrame\u001b[39m = [id-left: int, id: int ... 4 more fields]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dfjoin = leftdf.join(rightdf, leftdf(\"id\") === rightdf(\"value-right\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "278cc33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+--------+---+-----------+\n",
      "|id-left| id|value-left|id-right| id|value-right|\n",
      "+-------+---+----------+--------+---+-----------+\n",
      "|      3|  3|         3|       3|  3|          3|\n",
      "+-------+---+----------+--------+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfjoin.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b4ab4e",
   "metadata": {},
   "source": [
    "Using doric, errors can be detected at (Scala) compile-time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "22f30583",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cmd63.sc:1: type mismatch;\n",
      " found   : habla.doric.RightDoricColumn[String]\n",
      " required: habla.doric.RightDoricColumn[Int]\n",
      "def dfjoin = leftdf.join(rightdf, LeftDF.colInt(\"id\") === RightDF.colString(\"value-right\"), \"inner\")\n",
      "                                                                           ^Compilation Failed"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "Compilation Failed"
     ]
    }
   ],
   "source": [
    "// Scala will prevent this from compiling successfully\n",
    "def dfjoin = leftdf.join(rightdf, LeftDF.colInt(\"id\") === RightDF.colString(\"value-right\"), \"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23383a1b",
   "metadata": {},
   "source": [
    "or at DataFrame-construction time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7da4f22c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31mhabla.doric.DoricMultiError: Found 1 error in join\n\t\n\u001b[39m\n  habla.doric.syntax.DataFrameOps$DataframeSyntax$ErrorThrower.$anonfun$returnOrThrow$1(\u001b[32mDataFrameOps.scala\u001b[39m:\u001b[32m16\u001b[39m)\n  cats.data.Validated.fold(\u001b[32mValidated.scala\u001b[39m:\u001b[32m29\u001b[39m)\n  habla.doric.syntax.DataFrameOps$DataframeSyntax$ErrorThrower.returnOrThrow(\u001b[32mDataFrameOps.scala\u001b[39m:\u001b[32m16\u001b[39m)\n  habla.doric.syntax.DataFrameOps$DataframeSyntax.join(\u001b[32mDataFrameOps.scala\u001b[39m:\u001b[32m90\u001b[39m)\n  ammonite.$sess.cmd63$Helper.<init>(\u001b[32mcmd63.sc\u001b[39m:\u001b[32m1\u001b[39m)\n  ammonite.$sess.cmd63$.<init>(\u001b[32mcmd63.sc\u001b[39m:\u001b[32m7\u001b[39m)\n  ammonite.$sess.cmd63$.<clinit>(\u001b[32mcmd63.sc\u001b[39m:\u001b[32m-1\u001b[39m)"
     ]
    }
   ],
   "source": [
    "val dfjoin = leftdf.join(rightdf, LeftDF.colInt(\"id-left\") === RightDF.colInt(\"value-right\"), \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "23db125c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31mhabla.doric.DoricMultiError: Found 2 errors in join\n\tFound 1 error in Left dataframe\n\t\tCannot resolve column name \"id-left1\" among (id-left, id, value-left)\n\t\t\tlocated at . (cmd64.sc:1)\n\t\n\tFound 1 error in Right dataframe\n\t\tCannot resolve column name \"id-left1\" among (id-left, id, value-left)\n\t\t\tlocated at . (cmd64.sc:1)\n\t\n\u001b[39m\n  habla.doric.syntax.DataFrameOps$DataframeSyntax$ErrorThrower.$anonfun$returnOrThrow$1(\u001b[32mDataFrameOps.scala\u001b[39m:\u001b[32m16\u001b[39m)\n  cats.data.Validated.fold(\u001b[32mValidated.scala\u001b[39m:\u001b[32m29\u001b[39m)\n  habla.doric.syntax.DataFrameOps$DataframeSyntax$ErrorThrower.returnOrThrow(\u001b[32mDataFrameOps.scala\u001b[39m:\u001b[32m16\u001b[39m)\n  habla.doric.syntax.DataFrameOps$DataframeSyntax.join(\u001b[32mDataFrameOps.scala\u001b[39m:\u001b[32m90\u001b[39m)\n  ammonite.$sess.cmd64$Helper.<init>(\u001b[32mcmd64.sc\u001b[39m:\u001b[32m1\u001b[39m)\n  ammonite.$sess.cmd64$.<init>(\u001b[32mcmd64.sc\u001b[39m:\u001b[32m7\u001b[39m)\n  ammonite.$sess.cmd64$.<clinit>(\u001b[32mcmd64.sc\u001b[39m:\u001b[32m-1\u001b[39m)\n\u001b[31morg.apache.spark.sql.AnalysisException: Cannot resolve column name \"id-left1\" among (id-left, id, value-left)\u001b[39m\n  org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$resolveException(\u001b[32mDataset.scala\u001b[39m:\u001b[32m272\u001b[39m)\n  org.apache.spark.sql.Dataset.$anonfun$resolve$1(\u001b[32mDataset.scala\u001b[39m:\u001b[32m263\u001b[39m)\n  scala.Option.getOrElse(\u001b[32mOption.scala\u001b[39m:\u001b[32m189\u001b[39m)\n  org.apache.spark.sql.Dataset.resolve(\u001b[32mDataset.scala\u001b[39m:\u001b[32m263\u001b[39m)\n  org.apache.spark.sql.Dataset.col(\u001b[32mDataset.scala\u001b[39m:\u001b[32m1359\u001b[39m)\n  org.apache.spark.sql.Dataset.apply(\u001b[32mDataset.scala\u001b[39m:\u001b[32m1326\u001b[39m)\n  habla.doric.SparkType.$anonfun$validate$1(\u001b[32mSparkType.scala\u001b[39m:\u001b[32m21\u001b[39m)\n  habla.doric.package$LeftDoricColumn.$anonfun$$eq$eq$eq$1(\u001b[32mdoric.scala\u001b[39m:\u001b[32m65\u001b[39m)\n  habla.doric.syntax.DataFrameOps$DataframeSyntax.join(\u001b[32mDataFrameOps.scala\u001b[39m:\u001b[32m88\u001b[39m)\n  ammonite.$sess.cmd64$Helper.<init>(\u001b[32mcmd64.sc\u001b[39m:\u001b[32m1\u001b[39m)\n  ammonite.$sess.cmd64$.<init>(\u001b[32mcmd64.sc\u001b[39m:\u001b[32m7\u001b[39m)\n  ammonite.$sess.cmd64$.<clinit>(\u001b[32mcmd64.sc\u001b[39m:\u001b[32m-1\u001b[39m)"
     ]
    }
   ],
   "source": [
    "val dfjoin = leftdf.join(rightdf, LeftDF.colInt(\"id-left1\") === RightDF.colInt(\"value-right\"), \"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663e977c",
   "metadata": {},
   "source": [
    "As you can see, join doric expressions also enjoy all the goodies concerning error location :D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5b9ce4",
   "metadata": {},
   "source": [
    "If everything is well-typed, then the DataFrame constructed will be exactly the same than the one obtained using conventional column expressions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "27df74b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres65\u001b[39m: \u001b[32mDataFrame\u001b[39m = [id-left: int, id: int ... 4 more fields]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leftdf.join(rightdf, LeftDF.colInt(\"id\") === RightDF.colInt(\"id\"), \"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8523a5b7",
   "metadata": {},
   "source": [
    "As you can see, _join_ doric column expressions refer to the left and right DataFrames using the special objects `LeftDF` and `RightDF`, respectively. We can also refer to arbitrarily complex column expressions within the context of the left and right DataFrames, enclosing the expression between parenthesis. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dbd617e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31mhabla.doric.DoricMultiError: Found 1 error in join\n\tFound 1 error in Left dataframe\n\t\tCannot resolve column name \"id2\" among (id-left, id, value-left)\n\t\t\tlocated at . (cmd68.sc:1)\n\t\n\tFound 1 error in Right dataframe\n\t\tCannot resolve column name \"id2\" among (id-left, id, value-left)\n\t\t\tlocated at . (cmd68.sc:1)\n\t\n\u001b[39m\n  habla.doric.syntax.DataFrameOps$DataframeSyntax$ErrorThrower.$anonfun$returnOrThrow$1(\u001b[32mDataFrameOps.scala\u001b[39m:\u001b[32m16\u001b[39m)\n  cats.data.Validated.fold(\u001b[32mValidated.scala\u001b[39m:\u001b[32m29\u001b[39m)\n  habla.doric.syntax.DataFrameOps$DataframeSyntax$ErrorThrower.returnOrThrow(\u001b[32mDataFrameOps.scala\u001b[39m:\u001b[32m16\u001b[39m)\n  habla.doric.syntax.DataFrameOps$DataframeSyntax.join(\u001b[32mDataFrameOps.scala\u001b[39m:\u001b[32m90\u001b[39m)\n  ammonite.$sess.cmd68$Helper.<init>(\u001b[32mcmd68.sc\u001b[39m:\u001b[32m3\u001b[39m)\n  ammonite.$sess.cmd68$.<init>(\u001b[32mcmd68.sc\u001b[39m:\u001b[32m7\u001b[39m)\n  ammonite.$sess.cmd68$.<clinit>(\u001b[32mcmd68.sc\u001b[39m:\u001b[32m-1\u001b[39m)\n\u001b[31morg.apache.spark.sql.AnalysisException: Cannot resolve column name \"id2\" among (id-left, id, value-left)\u001b[39m\n  org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$resolveException(\u001b[32mDataset.scala\u001b[39m:\u001b[32m272\u001b[39m)\n  org.apache.spark.sql.Dataset.$anonfun$resolve$1(\u001b[32mDataset.scala\u001b[39m:\u001b[32m263\u001b[39m)\n  scala.Option.getOrElse(\u001b[32mOption.scala\u001b[39m:\u001b[32m189\u001b[39m)\n  org.apache.spark.sql.Dataset.resolve(\u001b[32mDataset.scala\u001b[39m:\u001b[32m263\u001b[39m)\n  org.apache.spark.sql.Dataset.col(\u001b[32mDataset.scala\u001b[39m:\u001b[32m1359\u001b[39m)\n  org.apache.spark.sql.Dataset.apply(\u001b[32mDataset.scala\u001b[39m:\u001b[32m1326\u001b[39m)\n  habla.doric.SparkType.$anonfun$validate$1(\u001b[32mSparkType.scala\u001b[39m:\u001b[32m21\u001b[39m)\n  habla.doric.package$LeftDoricColumn.$anonfun$$eq$eq$eq$1(\u001b[32mdoric.scala\u001b[39m:\u001b[32m65\u001b[39m)\n  habla.doric.syntax.DataFrameOps$DataframeSyntax.join(\u001b[32mDataFrameOps.scala\u001b[39m:\u001b[32m88\u001b[39m)\n  ammonite.$sess.cmd68$Helper.<init>(\u001b[32mcmd68.sc\u001b[39m:\u001b[32m3\u001b[39m)\n  ammonite.$sess.cmd68$.<init>(\u001b[32mcmd68.sc\u001b[39m:\u001b[32m7\u001b[39m)\n  ammonite.$sess.cmd68$.<clinit>(\u001b[32mcmd68.sc\u001b[39m:\u001b[32m-1\u001b[39m)"
     ]
    }
   ],
   "source": [
    "val leftCol = LeftDF.colString(\"id2\")\n",
    "val rightCol = RightDF(/* complex column expression here*/ colInt(\"id\").cast[String])\n",
    "leftdf.join(rightdf, leftCol === rightCol, \"inner\").show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad977f4",
   "metadata": {},
   "source": [
    "and, as this example also shows, we can also decompose doric join expressions in different functions so as to obtain more modular designs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0342bc0d",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**>>>>>>> remote**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": {
    "local_id": "477636fc",
    "remote_id": "b13cb054"
   },
   "metadata": {},
   "outputs": [],
   "source": [
    "<<<<<<< local\n",
    "val leftdf = List((1, 1, \"hi\"), (2, 2, \"bye\"), (3, 3, \"3\")).toDF(\"id-left\", \"id\", \"value-left\")\n",
    "val rightdf = List((1, 1, \"hi\"), (2, 2, \"bye\"), (3, 3, \"3\")).toDF(\"id-right\", \"id\", \"value-right\")\n",
    "=======\n",
    "val leftdf2 = List((\"1\",\"hi\"), (\"2\", \"bye\")).toDF(\"id\", \"value-left\")\n",
    "val rightdf2 = List((1,\"hi\"), (2, \"bye\")).toDF(\"id\", \"value-right\")\n",
    ">>>>>>> remote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c664e9ec",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**<<<<<<< local**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b020da",
   "metadata": {},
   "source": [
    "the following equi-join expressions, where we use different mechanisms to refer to the corresponding columns, compile and run without problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "41f0fc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres44_0\u001b[39m: \u001b[32mDataFrame\u001b[39m = [id-left: int, id: int ... 4 more fields]\n",
       "\u001b[36mres44_1\u001b[39m: \u001b[32mDataFrame\u001b[39m = [id-left: int, id: int ... 4 more fields]\n",
       "\u001b[36mres44_2\u001b[39m: \u001b[32mDataFrame\u001b[39m = [id-left: int, id: int ... 4 more fields]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leftdf.join(rightdf, f.col(\"id-left\") === f.col(\"id-right\"))\n",
    "leftdf.join(rightdf, leftdf(\"id\") === rightdf(\"id\"))\n",
    "leftdf.alias(\"left\").join(rightdf.alias(\"right\"), f.col(\"left.id\") === f.col(\"right.id\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce498a34",
   "metadata": {},
   "source": [
    "However, if some column name or type is wrong, then errors will be shown too late, or implicit type casts will be applied. For instance, the following DataFrame compiles in Spark and runs with garbage results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e7dc0133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mdfjoin\u001b[39m: \u001b[32mDataFrame\u001b[39m = [id-left: int, id: int ... 4 more fields]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dfjoin = leftdf.join(rightdf, leftdf(\"id\") === rightdf(\"value-right\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "278cc33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+--------+---+-----------+\n",
      "|id-left| id|value-left|id-right| id|value-right|\n",
      "+-------+---+----------+--------+---+-----------+\n",
      "|      3|  3|         3|       3|  3|          3|\n",
      "+-------+---+----------+--------+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfjoin.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b4ab4e",
   "metadata": {},
   "source": [
    "Using doric, errors can be detected at (Scala) compile-time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "22f30583",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cmd63.sc:1: type mismatch;\n",
      " found   : habla.doric.RightDoricColumn[String]\n",
      " required: habla.doric.RightDoricColumn[Int]\n",
      "def dfjoin = leftdf.join(rightdf, LeftDF.colInt(\"id\") === RightDF.colString(\"value-right\"), \"inner\")\n",
      "                                                                           ^Compilation Failed"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "Compilation Failed"
     ]
    }
   ],
   "source": [
    "// Scala will prevent this from compiling successfully\n",
    "def dfjoin = leftdf.join(rightdf, LeftDF.colInt(\"id\") === RightDF.colString(\"value-right\"), \"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23383a1b",
   "metadata": {},
   "source": [
    "or at DataFrame-construction time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7da4f22c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31mhabla.doric.DoricMultiError: Found 1 error in join\n\t\n\u001b[39m\n  habla.doric.syntax.DataFrameOps$DataframeSyntax$ErrorThrower.$anonfun$returnOrThrow$1(\u001b[32mDataFrameOps.scala\u001b[39m:\u001b[32m16\u001b[39m)\n  cats.data.Validated.fold(\u001b[32mValidated.scala\u001b[39m:\u001b[32m29\u001b[39m)\n  habla.doric.syntax.DataFrameOps$DataframeSyntax$ErrorThrower.returnOrThrow(\u001b[32mDataFrameOps.scala\u001b[39m:\u001b[32m16\u001b[39m)\n  habla.doric.syntax.DataFrameOps$DataframeSyntax.join(\u001b[32mDataFrameOps.scala\u001b[39m:\u001b[32m90\u001b[39m)\n  ammonite.$sess.cmd63$Helper.<init>(\u001b[32mcmd63.sc\u001b[39m:\u001b[32m1\u001b[39m)\n  ammonite.$sess.cmd63$.<init>(\u001b[32mcmd63.sc\u001b[39m:\u001b[32m7\u001b[39m)\n  ammonite.$sess.cmd63$.<clinit>(\u001b[32mcmd63.sc\u001b[39m:\u001b[32m-1\u001b[39m)"
     ]
    }
   ],
   "source": [
    "val dfjoin = leftdf.join(rightdf, LeftDF.colInt(\"id-left\") === RightDF.colInt(\"value-right\"), \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "23db125c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31mhabla.doric.DoricMultiError: Found 2 errors in join\n\tFound 1 error in Left dataframe\n\t\tCannot resolve column name \"id-left1\" among (id-left, id, value-left)\n\t\t\tlocated at . (cmd64.sc:1)\n\t\n\tFound 1 error in Right dataframe\n\t\tCannot resolve column name \"id-left1\" among (id-left, id, value-left)\n\t\t\tlocated at . (cmd64.sc:1)\n\t\n\u001b[39m\n  habla.doric.syntax.DataFrameOps$DataframeSyntax$ErrorThrower.$anonfun$returnOrThrow$1(\u001b[32mDataFrameOps.scala\u001b[39m:\u001b[32m16\u001b[39m)\n  cats.data.Validated.fold(\u001b[32mValidated.scala\u001b[39m:\u001b[32m29\u001b[39m)\n  habla.doric.syntax.DataFrameOps$DataframeSyntax$ErrorThrower.returnOrThrow(\u001b[32mDataFrameOps.scala\u001b[39m:\u001b[32m16\u001b[39m)\n  habla.doric.syntax.DataFrameOps$DataframeSyntax.join(\u001b[32mDataFrameOps.scala\u001b[39m:\u001b[32m90\u001b[39m)\n  ammonite.$sess.cmd64$Helper.<init>(\u001b[32mcmd64.sc\u001b[39m:\u001b[32m1\u001b[39m)\n  ammonite.$sess.cmd64$.<init>(\u001b[32mcmd64.sc\u001b[39m:\u001b[32m7\u001b[39m)\n  ammonite.$sess.cmd64$.<clinit>(\u001b[32mcmd64.sc\u001b[39m:\u001b[32m-1\u001b[39m)\n\u001b[31morg.apache.spark.sql.AnalysisException: Cannot resolve column name \"id-left1\" among (id-left, id, value-left)\u001b[39m\n  org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$resolveException(\u001b[32mDataset.scala\u001b[39m:\u001b[32m272\u001b[39m)\n  org.apache.spark.sql.Dataset.$anonfun$resolve$1(\u001b[32mDataset.scala\u001b[39m:\u001b[32m263\u001b[39m)\n  scala.Option.getOrElse(\u001b[32mOption.scala\u001b[39m:\u001b[32m189\u001b[39m)\n  org.apache.spark.sql.Dataset.resolve(\u001b[32mDataset.scala\u001b[39m:\u001b[32m263\u001b[39m)\n  org.apache.spark.sql.Dataset.col(\u001b[32mDataset.scala\u001b[39m:\u001b[32m1359\u001b[39m)\n  org.apache.spark.sql.Dataset.apply(\u001b[32mDataset.scala\u001b[39m:\u001b[32m1326\u001b[39m)\n  habla.doric.SparkType.$anonfun$validate$1(\u001b[32mSparkType.scala\u001b[39m:\u001b[32m21\u001b[39m)\n  habla.doric.package$LeftDoricColumn.$anonfun$$eq$eq$eq$1(\u001b[32mdoric.scala\u001b[39m:\u001b[32m65\u001b[39m)\n  habla.doric.syntax.DataFrameOps$DataframeSyntax.join(\u001b[32mDataFrameOps.scala\u001b[39m:\u001b[32m88\u001b[39m)\n  ammonite.$sess.cmd64$Helper.<init>(\u001b[32mcmd64.sc\u001b[39m:\u001b[32m1\u001b[39m)\n  ammonite.$sess.cmd64$.<init>(\u001b[32mcmd64.sc\u001b[39m:\u001b[32m7\u001b[39m)\n  ammonite.$sess.cmd64$.<clinit>(\u001b[32mcmd64.sc\u001b[39m:\u001b[32m-1\u001b[39m)"
     ]
    }
   ],
   "source": [
    "val dfjoin = leftdf.join(rightdf, LeftDF.colInt(\"id-left1\") === RightDF.colInt(\"value-right\"), \"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663e977c",
   "metadata": {},
   "source": [
    "As you can see, join doric expressions also enjoy all the goodies concerning error location :D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5b9ce4",
   "metadata": {},
   "source": [
    "If everything is well-typed, then the DataFrame constructed will be exactly the same than the one obtained using conventional column expressions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "27df74b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres65\u001b[39m: \u001b[32mDataFrame\u001b[39m = [id-left: int, id: int ... 4 more fields]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leftdf.join(rightdf, LeftDF.colInt(\"id\") === RightDF.colInt(\"id\"), \"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8523a5b7",
   "metadata": {},
   "source": [
    "As you can see, _join_ doric column expressions refer to the left and right DataFrames using the special objects `LeftDF` and `RightDF`, respectively. We can also refer to arbitrarily complex column expressions within the context of the left and right DataFrames, enclosing the expression between parenthesis. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dbd617e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31mhabla.doric.DoricMultiError: Found 1 error in join\n\tFound 1 error in Left dataframe\n\t\tCannot resolve column name \"id2\" among (id-left, id, value-left)\n\t\t\tlocated at . (cmd68.sc:1)\n\t\n\tFound 1 error in Right dataframe\n\t\tCannot resolve column name \"id2\" among (id-left, id, value-left)\n\t\t\tlocated at . (cmd68.sc:1)\n\t\n\u001b[39m\n  habla.doric.syntax.DataFrameOps$DataframeSyntax$ErrorThrower.$anonfun$returnOrThrow$1(\u001b[32mDataFrameOps.scala\u001b[39m:\u001b[32m16\u001b[39m)\n  cats.data.Validated.fold(\u001b[32mValidated.scala\u001b[39m:\u001b[32m29\u001b[39m)\n  habla.doric.syntax.DataFrameOps$DataframeSyntax$ErrorThrower.returnOrThrow(\u001b[32mDataFrameOps.scala\u001b[39m:\u001b[32m16\u001b[39m)\n  habla.doric.syntax.DataFrameOps$DataframeSyntax.join(\u001b[32mDataFrameOps.scala\u001b[39m:\u001b[32m90\u001b[39m)\n  ammonite.$sess.cmd68$Helper.<init>(\u001b[32mcmd68.sc\u001b[39m:\u001b[32m3\u001b[39m)\n  ammonite.$sess.cmd68$.<init>(\u001b[32mcmd68.sc\u001b[39m:\u001b[32m7\u001b[39m)\n  ammonite.$sess.cmd68$.<clinit>(\u001b[32mcmd68.sc\u001b[39m:\u001b[32m-1\u001b[39m)\n\u001b[31morg.apache.spark.sql.AnalysisException: Cannot resolve column name \"id2\" among (id-left, id, value-left)\u001b[39m\n  org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$resolveException(\u001b[32mDataset.scala\u001b[39m:\u001b[32m272\u001b[39m)\n  org.apache.spark.sql.Dataset.$anonfun$resolve$1(\u001b[32mDataset.scala\u001b[39m:\u001b[32m263\u001b[39m)\n  scala.Option.getOrElse(\u001b[32mOption.scala\u001b[39m:\u001b[32m189\u001b[39m)\n  org.apache.spark.sql.Dataset.resolve(\u001b[32mDataset.scala\u001b[39m:\u001b[32m263\u001b[39m)\n  org.apache.spark.sql.Dataset.col(\u001b[32mDataset.scala\u001b[39m:\u001b[32m1359\u001b[39m)\n  org.apache.spark.sql.Dataset.apply(\u001b[32mDataset.scala\u001b[39m:\u001b[32m1326\u001b[39m)\n  habla.doric.SparkType.$anonfun$validate$1(\u001b[32mSparkType.scala\u001b[39m:\u001b[32m21\u001b[39m)\n  habla.doric.package$LeftDoricColumn.$anonfun$$eq$eq$eq$1(\u001b[32mdoric.scala\u001b[39m:\u001b[32m65\u001b[39m)\n  habla.doric.syntax.DataFrameOps$DataframeSyntax.join(\u001b[32mDataFrameOps.scala\u001b[39m:\u001b[32m88\u001b[39m)\n  ammonite.$sess.cmd68$Helper.<init>(\u001b[32mcmd68.sc\u001b[39m:\u001b[32m3\u001b[39m)\n  ammonite.$sess.cmd68$.<init>(\u001b[32mcmd68.sc\u001b[39m:\u001b[32m7\u001b[39m)\n  ammonite.$sess.cmd68$.<clinit>(\u001b[32mcmd68.sc\u001b[39m:\u001b[32m-1\u001b[39m)"
     ]
    }
   ],
   "source": [
    "val leftCol = LeftDF.colString(\"id2\")\n",
    "val rightCol = RightDF(/* complex column expression here*/ colInt(\"id\").cast[String])\n",
    "leftdf.join(rightdf, leftCol === rightCol, \"inner\").show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad977f4",
   "metadata": {},
   "source": [
    "and, as this example also shows, we can also decompose doric join expressions in different functions so as to obtain more modular designs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebc31b7",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**=======**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d32707b",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**>>>>>>> remote**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ae160d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala (2.12)",
   "language": "scala",
   "name": "scala212"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
